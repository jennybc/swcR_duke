% Block 03: Data aggregation and reshaping
% Jenny Bryan
% 2013 August

```{r}
## data import from URL
#gdURL <- "http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt"
#gDat <- read.delim(file = gdURL)
## alternatively, work with a copy saved locally
## I can't simply read from working directory because this webpage is not being
## generated in the directory / RStudio project where I'm working living during
## SWC
gDat <- read.delim("../../data/gapminder/gapminderDataFiveYear.txt")
str(gDat)
```

### Data aggregation

If you feel the urge to pull out a little snippet of a data.frame:
```{r}
(snippet <- subset(gDat, country == "Canada"))
```
Stop and ask yourself ...
Do I want to create sub-data.frames for each level of some factor (or unique combination of several factors) ... in order to compute or graph something?
If YES, use data aggregation techniques or conditioning in lattice plots or facetting in ggplot2 plots -- don’t subset the data.frame.
If NO, then maybe you really do need to subset the data.frame. Use subset() as we've discussed and go on your merry way.

Good reference: Chapter 8 (“Data Aggregation”) of Spector (2008). This whole book is extremely valuable.

For those situations when you need to so something for various chunks of your dataset, the best method depends on the nature of these chunks

+------------------------------------------------------------+-------------------------------------------+
| chunks are ...                                             | relevant functions                        |
+============================================================+===========================================+
| rows, columns, etc. of matrix/array                        | apply                                     |
+------------------------------------------------------------+-------------------------------------------+
| components of a list (includes variables in a data.frame!) | sapply, lapply                            |
+------------------------------------------------------------+-------------------------------------------+
| induced by levels of one or more factor(s)                 | tapply, by, split (+ [sl]apply, aggregate |
+------------------------------------------------------------+-------------------------------------------+

Example of computing summaries for rows and columns of a matrix

```{r}
(jCountries <- sort(c('Canada', 'United States', 'Mexico')))
tinyDat <- subset(gDat, country %in% jCountries)
str(tinyDat)                   # 'data.frame': 36 obs. of 6 variables:
(nY <- length(unique(tinyDat$year)))    # 12 years
jLifeExp <- matrix(tinyDat$lifeExp, nrow = nY)
colnames(jLifeExp) <- jCountries
rownames(jLifeExp) <- tinyDat$year[1:nY]
jLifeExp
apply(jLifeExp, 1, mean)
rowMeans(jLifeExp)#see also rowSums, colMeans, colSums
apply(jLifeExp, 2, median)
jCountries[apply(jLifeExp, 1, which.max)]
```

Operating on each variable in a data.frame -- a bit awkward because the whole point of data.frames is to hold disparate variables, so the same functions don't always *make sense* to apply to every variable in a data.frame. But I press on.

```{r}
sapply(gDat, summary)# artificial because summary(gDat) achieves same
sapply(gDat, is.numeric)
sapply(gDat, function(x) sum(is.na(x)))
```

I can get a new data.frame holding only the numeric variables.
MAKE THIS A CHALLENGE ... THE CREATION OF gDatNum.

```{r}
gDatNum <- subset(gDat, select = sapply(gDat, is.numeric))
str(gDatNum)
```

Gives a better stage for showing off `sapply()` and `lapply()`

```{r}
sapply(gDatNum, median)
lapply(gDatNum, median)
```
Note that `sapply()` attempts to tidy up after itself, where as `lapply()` always returns a list. Notice how plays out when your computing more than one number
```{r}
sapply(gDatNum, range)
lapply(gDatNum, range)
```

Let's say we want to get the maximum life expectancy for each continent.

```{r}
tapply(gDat$lifeExp, gDat$continent, max) # a drag to type
with(gDat, # a chance to show with
     tapply(lifeExp, continent, max))
```
The function you want to apply to the life expectancies for each continent can be built-in, like `max()` above, a custom function you've written, or a custom function specified 'on the fly'. Here's how I would count the number of countries in this dataset for each continent.

```{r}
with(gDat,
     tapply(country, continent, function(x) {
       length(unique(x))
     }))
```
Unfortunately the output of `tapply()` often requires tidying.
```{r}
(rangeLifeExp <- with(gDat, tapply(lifeExp, continent, range)))
str(rangeLifeExp)
```
It would be nice to have a matrix (or data.frame) with one row (or column) per continent and one column (or row) for the min life exp and one for max. You could stack up rows and columns to make matrices and data.frames, assuming the type of data and dimensions are tractable.
```{r}
rbind(rangeLifeExp[[1]], rangeLifeExp[[2]],
      rangeLifeExp[[3]], rangeLifeExp[[4]],
      rangeLifeExp[[5]])
```
Problem is ...this approach does not scale well at all. Will soon drive you nuts. There is an obscure-sounding but extremely useful alternative.
```{r}
leByCont <- do.call(rbind, rangeLifeExp)
colnames(leByCont) <- c("min", "max")
leByCont
```
We might still need to give decent column (variable) names, like "min" and "max", but this is still progress. So `lapply()` had a tidied up version `sapply()` but the analogous function does not exist for `tapply()`. It's up to you and `do.call()` helps a lot.

Finally, it would be most natural if `leByCont` were a data.frame and if the continent were present as a factor, with the same levels and level order as `gDat` itself, instead of as rownames.

```{r}
leByCont <- data.frame(leByCont)
leByCont <- with(leByCont,
                 data.frame(continent = rownames(leByCont),
                            min, max))
str(leByCont)
```

This issue of hard-to-predict, less-than-ideal stuff being returned from data aggregation functions is significant. The add-on package [`plyr`](http://plyr.had.co.nz) addresses this and more. I am just starting to use it now and I recommend you wise up faster than I did and do the same.

Let's try it out. Also gives us a chance to install an add-on package. Here's how to do so at the command line. I save these commands in a script, like I do everything else, so that it's easy for me re-install all the add-on packages I like whenever I update R.

```{r, eval=FALSE}
install.packages(pkgs = "plyr")
```
There are also RStudio-y ways to install packages. Once a package is installed, it still has to be loaded (unless it's one of the automatically loaded base packages). You can make all sorts of persistent changes to your set-up, including which packages are loaded by default, via `.Rprofile`. For now, we'll just load 'by hand'.
```{r}
library(plyr)
#library(help = "plyr")
```
Now we'll emulate what we did above using the `ddply()` function from `plyr`.
```{r}
ddply(gDat, .(continent), summarise, median = median(lifeExp))
leByCont2 <- ddply(gDat, .(continent), summarise, min = min(lifeExp), max = max(lifeExp))
leByCont2
str(leByCont)
str(leByCont2)
```

Now let's fit a linear regression of life expectancy on year within country. I just want to retain the intercepts and slopes.
```{r}
lm(lifeExp ~ year, gDat, subset = country == "Canada")
(yearMin <- min(gDat$year))
lm(lifeExp ~ I(year - yearMin), gDat, subset = country == "Canada")
coef(lm(lifeExp ~ I(year - yearMin), gDat, subset = country == "Canada"))
jFun <- function(z) {
  yearMin <- min(z$year)
  jCoef <- coef(lm(lifeExp ~ I(year - yearMin), data = z))
  names(jCoef) <- c("intercept", "slope")
  return(jCoef)
  }
jFun(subset(gDat, country == "Canada"))
gCoef <- ddply(gDat, .(country), jFun)
str(gCoef)
gCoef <- ddply(gDat, .(country, continent), jFun)
str(gCoef)
tail(gCoef)
```
Now we could explore these slopes and intercepts.

```{r}
library(lattice)
xyplot(slope ~ intercept, gCoef)
xyplot(slope ~ intercept, gCoef, group = continent, auto.key = TRUE)
xyplot(slope ~ intercept, gCoef, group = continent, auto.key = TRUE, type = c("p", "r"))
(leSlopeByCont <- ddply(gCoef, .(continent), summarise,
                        minSlope = min(slope), medSlope = median(slope), maxSlope = max(slope)))
## ? get the country with the min or max slope within each continent ?
```

### Data reshaping

Frequently data needs to be reshaped. General from short-and-fat to tall-and-skinny. In my life the most common reasons for this are for modelling and graphing. Consider the data.frame we made earlier giving the min, median, and max (variables or columns) life expectancy slope for each of the 5 continents (rows or observations). Imagine I want to make a figure with min = 0 , median = 0.5, max = 1 on the x axis, life expectancy on the yaxis, and connect the dots for each continent. It turns out this is much easier if the data is rearranged.

```{r}
leSlopeByContTall <-
  with(leSlopeByCont,
         data.frame(continent = continent,
                    slope = c(minSlope, medSlope, maxSlope),       
                    what = factor(rep(c("min", "med", "max"), each = nrow(leSlopeByCont)),
                                  levels = c("min", "med", "max"))))
str(leSlopeByContTall)
leSlopeByContTall
```
Now we can make the plot
```{r}
library(lattice)
stripplot(slope ~ what, leSlopeByContTall)
stripplot(slope ~ what, leSlopeByContTall,
          groups = continent, auto.key = TRUE,
          grid = TRUE, type = "b")
```
Notice we exploited recycling for continent.

What I did above was cumbersome but I took full control. I have dabbled with the built-in functions `stack()` and `reshape()` and found them more trouble than they were worth. If I abandon my primitive approach, it would be in favor of functions in the add-on package [`reshape`](http://had.co.nz/reshape/), which is hear good things about. This might be another case, like `plyr`, where you should skip over the tools in base R.

Let's try `reshape`. http://had.co.nz/reshape/
```{r}
library(reshape)
#TO ADD
```


### Using base R data aggregation tools to get the intercept and slope for each country's linear regression of life expectancy on year

`tapply()` could only compute an a single variable -- `lifeExp` in examples above. If you need to work with multiple variables consider `by()`. Here's how I would do simple linear regression of life expectancy on year for each country. I'm also storing just the estimated parameters, ie intercept and slope. We'll return to this towards the end of the day.


```{r}
(yearMin <- min(gDat$year))
coefEst <- by(gDat, gDat$country, function(cty) {
  coef(lm(lifeExp ~ I(year - yearMin), data = cty))
})
head(coefEst)
```
We need to clean up again.
```{r}
coefEst <- data.frame(do.call(rbind, coefEst))
head(coefEst)
```
I'd rather have the country names as an actual variable (vs. as row names) and the variable names are awful.
```{r}
coefEst <-
  data.frame(country = factor(rownames(coefEst),
                              levels = levels(gDat$country)),
             coefEst)
names(coefEst) <- c("country", "intercept", "slope")
rownames(coefEst) <- NULL
head(coefEst)
```
To really polish this off, I wish I had the continent information. `match()` is very useful for table look-up tasks.
```{r}
foo <- match(coefEst$country, gDat$country)
head(foo)
```
`foo` says that the first instance of "Afghanistan" as a country in `gDat` is in row 1. The first instance of "Albania" in row 13, etc etc. So with those row numbers in hand, I can index the continent variable from `gDat` to get a continent variable suitable for use in `coefEst`.
```{r}
head(gDat$country[foo])
```
I could add this to `coefEst` like so:
```{r, eval=FALSE}
coefEst$continent <- gDat$continent[foo]
```
`merge()` is another function that is useful for these operations.